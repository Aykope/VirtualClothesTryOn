import os
import cv2
import mediapipe as mp
import numpy as np

# Functions for clothes and accessories
def cloth_1(landmarks):
    im_path = os.path.join(os.path.dirname(__file__), 'white_cloth', 'cloth1', 'cloth1.png')
    threshold = [200, 255]
    key_points = [
        (239, 91),  # Left shoulder
        (564, 91),  # Right shoulder
        (309, 344),  # Left hip
        (500, 344)  # Right hip
    ]
    dst_points = np.array([
        (landmarks[12][0], landmarks[12][1]),  # Left shoulder
        (landmarks[11][0], landmarks[11][1]),  # Right shoulder
        (landmarks[24][0], landmarks[24][1]),  # Left hip
        (landmarks[23][0], landmarks[23][1])   # Right hip
    ], dtype=np.float32)
    return im_path, threshold, key_points, dst_points

def cloth_2(landmarks):
    im_path = os.path.join(os.path.dirname(__file__), 'white_cloth', 'cloth2', 'cloth2.bmp')
    threshold = [200, 255]
    key_points = [
        (258, 109),  # Left shoulder
        (702, 109),  # Right shoulder
        (300, 803),  # Left hip
        (600, 803)   # Right hip
    ]
    dst_points = np.array([
        (landmarks[12][0], landmarks[12][1]),  # Left shoulder
        (landmarks[11][0], landmarks[11][1]),  # Right shoulder
        (landmarks[24][0], landmarks[24][1]),  # Left hip
        (landmarks[23][0], landmarks[23][1])   # Right hip
    ], dtype=np.float32)
    return im_path, threshold, key_points, dst_points

def cloth_3(landmarks):
    im_path = os.path.join(os.path.dirname(__file__), 'white_cloth', 'cloth3', 'cloth3.jpg')
    threshold = [200, 255]
    key_points = [
        (278, 158),  # Left shoulder
        (732, 157),  # Right shoulder
        (349, 680),  # Left hip
        (650, 680)   # Right hip
    ]
    dst_points = np.array([
        (landmarks[12][0], landmarks[12][1]),  # Left shoulder
        (landmarks[11][0], landmarks[11][1]),  # Right shoulder
        (landmarks[24][0], landmarks[24][1]),  # Left hip
        (landmarks[23][0], landmarks[23][1])   # Right hip
    ], dtype=np.float32)
    return im_path, threshold, key_points, dst_points

def cloth_4(landmarks):
    im_path = os.path.join(os.path.dirname(__file__), 'white_cloth', 'cloth4', 'cloth4.jpg')
    threshold = [200, 255]
    key_points = [
        (388, 488),  # Left shoulder
        (895, 487),  # Right shoulder
        (471, 1200),  # Left hip
        (808, 1200)   # Right hip
    ]
    dst_points = np.array([
        (landmarks[12][0], landmarks[12][1]),  # Left shoulder
        (landmarks[11][0], landmarks[11][1]),  # Right shoulder
        (landmarks[24][0], landmarks[24][1]),  # Left hip
        (landmarks[23][0], landmarks[23][1])   # Right hip
    ], dtype=np.float32)
    return im_path, threshold, key_points, dst_points

def cloth_5(landmarks):
    im_path = os.path.join(os.path.dirname(__file__), 'white_cloth', 'cloth5', 'cloth5.jpg')
    threshold = [200, 255]
    key_points = [
        (130, 74),   # Left shoulder
        (380, 74),   # Right shoulder
        (142, 474),  # Left hip
        (367, 474)   # Right hip
    ]
    dst_points = np.array([
        (landmarks[12][0], landmarks[12][1]),  # Left shoulder
        (landmarks[11][0], landmarks[11][1]),  # Right shoulder
        (landmarks[24][0], landmarks[24][1]),  # Left hip
        (landmarks[23][0], landmarks[23][1])   # Right hip
    ], dtype=np.float32)
    return im_path, threshold, key_points, dst_points

def load_item_data(item_function, landmarks):
    im_path, threshold, key_points, dst_points = item_function(landmarks)
    item_img = cv2.imread(im_path)
    if item_img is None:
        print(f"Failed to load image from {im_path}")
        return None, None, None
    gray = cv2.cvtColor(item_img, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray, threshold[0], threshold[1], cv2.THRESH_BINARY_INV)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    mask = np.zeros_like(item_img)
    cv2.drawContours(mask, contours, -1, (255, 255, 255), -1)
    item_extracted = cv2.bitwise_and(item_img, mask)
    return item_extracted, key_points, dst_points

# Get pose landmarks
def get_pose_landmarks(frame):
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = pose.process(frame_rgb)
    if result.pose_landmarks:
        landmarks = []
        for lm in result.pose_landmarks.landmark:
            x, y = int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])
            landmarks.append((x, y))
        return landmarks, result
    return None, None

def warp_item(item_img, src_points, dst_points, frame):
    matrix = cv2.getPerspectiveTransform(np.array(src_points, dtype=np.float32), np.array(dst_points, dtype=np.float32))
    warped_item = cv2.warpPerspective(item_img, matrix, (frame.shape[1], frame.shape[0]))
    return warped_item

# Initialize Mediapipe Pose
mp_pose = mp.solutions.pose
pose = mp_pose.Pose()

# Open the camera
cap = cv2.VideoCapture(0)

# Select the item to display
# 1: cloth_1, 2: cloth_2, 3: cloth_3, 4: cloth_4, 5: cloth_5
selected_cloth = 2  # Select cloth

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    landmarks, result = get_pose_landmarks(frame)

    if landmarks:
        if selected_cloth == 1:
            item_img, src_points, dst_points = load_item_data(cloth_1, landmarks)
        elif selected_cloth == 2:
            item_img, src_points, dst_points = load_item_data(cloth_2, landmarks)
        elif selected_cloth == 3:
            item_img, src_points, dst_points = load_item_data(cloth_3, landmarks)
        elif selected_cloth == 4:
            item_img, src_points, dst_points = load_item_data(cloth_4, landmarks)
        elif selected_cloth == 5:
            item_img, src_points, dst_points = load_item_data(cloth_5, landmarks)
        
        if item_img is not None:
            warped_item = warp_item(item_img, src_points, dst_points, frame)
            mask = np.any(warped_item != 0, axis=-1)
            frame[mask] = warped_item[mask]

    cv2.imshow('Virtual Clothes Fitting', frame)
    if cv2.waitKey(10) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
